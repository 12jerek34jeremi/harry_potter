{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "   Hi, I'm Jędrzej Chmiel and this is a description of my latest project, \"Harry Potter Chapter Writer\". It's purpose is to create a Neural Network that will first learn this magic word and then will write it's own chapter.\n",
    "\n",
    "   How it is done (short overview):\n",
    "1) Firstly, I bought all seven Harry Potter books (in soft copy) and saved them as pdf. Then I copied all text from each pdf and saved it as txt file. Then, using regular expression, I removed all unnecessary things from those txt files. By unnecessary things, I mean stuff like chapter titles and page numbers. I also took care of hyphenation, underscores and many others, so that word_tokenize function from nltk.tokenizer module can easily tokenize a file.\n",
    "\n",
    "2) Secondly, I use word_tokenize function from tokenize from nltk package to split text files into words. I gave each unique word an unique id. From this time on, I will call those unique id tokens. Token is an integer number and word is a string.\n",
    "\n",
    "3) After that, I used trainable embedding (torch.nn.Embedding) to transform tokens to dense vectors. To transform dense vector, which represents some word, back to a token, I used fully-connected layers. From now on I will call dense vector which represents some word an \"embedding vector\". \n",
    "\n",
    "4) Then, I used technique called \"Batch of Words\" to train embedding, so that those embedding vectors really encode usable information and aren' just a course of random numbers.\n",
    "\n",
    "5) To write a chapter, I'm going to use just LSTM's. Input to one LSTM cell will be an embedding vector, output of one LSTM cell will also be an embedding vector. I will use projection so that hidden state and cell state can be of different dimensions. Then I will use first six books to train this LSTM to predict next word given nine prevoius words. \n",
    "\n",
    "6) Finally, I'm going to \"show\" this LSTM cell first six Harry Potter books and first two chapters of seventh book. I'm going to predict tenth word of third chapter based on first nine words of this chapter, then predict 11-th word of third chapter using 8 'real' words and one previously  predicted word, then predict 12-th word using 7 'real' words and two previously predicted words and so on... Finally network is going to predict next word based only on previously  predicted word. I will apply this step about 4'000 times to write a chapter. Let's clarify what do I mean by saying \"showing\" first six books. First six books are about 1'127'687 words. First I predict second word using first word and save cell state and hidden state. Then i predict third word using second real word, saved hidden state, saved cell state and save new hidden and saved hidden state. I will apply this step (predicting next word using previous real word, most recent hidden and cell states and saving new hidden and cell state) 1'127'685 more times. This way I hope LSTM will learn about wizard word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step One\n",
    "I bought all seven Harry Potter books (in soft copy) and saved them as pdf. Then I copied all text from each pdf and saved it as .txt file. We need a function which will \"prepare\" a book for us. Prepare means removing things like chapter titles and page numbers. I wrote a function which just do so. Here is how this function look like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_harry_book(input_directory: str,\n",
    "                       output_directory: str,\n",
    "                       format_mode: int,\n",
    "                       remove_new_lines: bool = True,\n",
    "                       to_lower=True,\n",
    "                       remove_hyphens=True):\n",
    "\n",
    "    patterns = []\n",
    "    patterns.append((re.compile(r'[\"\\”\\“]'), '\"'))\n",
    "    patterns.append((re.compile(r\"[\\'\\’\\`\\´]\"), \"'\"))\n",
    "    patterns.append((re.compile(r\"[\\,\\¸]\"), ','))\n",
    "    patterns.append((re.compile(r'((\\. ?){2,})|…'), ' ... '))\n",
    "\n",
    "    if format_mode == 1:\n",
    "        patterns.append((re.compile(\n",
    "            r'\\nPage [0-9]+ of [0-9]+\\nGet free e-books and video tutorials at www\\.passuneb\\.com\\n'\n",
    "        ), ' '))\n",
    "        patterns.append((re.compile(r'\\n?CHAPTER .*\\n*\\n'), '\\n'))\n",
    "    elif format_mode == 2:\n",
    "        patterns.append((re.compile(\n",
    "            r'\\nC H A P T E R .+\\naTHEaPAGEaSIGNa [0-9]+ aTHEaPAGEaSIGNa\\n[A-Z ]+\\n'\n",
    "        ), ' '))\n",
    "        patterns.append((re.compile(\n",
    "            r'\\n[A-Z \\.\\'\\\"\\,\\-]*\\naTHEaPAGEaSIGNa [0-9]+ aTHEaPAGEaSIGNa\\n'),\n",
    "                         ' '))\n",
    "    elif format_mode == 3:\n",
    "        patterns.append((re.compile(\n",
    "            r\"\\naNUMBERaSIXaSIGNa [0-9]+ aNUMBERaSIXaSIGNa\\nC H A P T E R [A-Z -]+\\n[A-Z ,.’'-]+\\n\"\n",
    "        ), ' '))\n",
    "        patterns.append((re.compile(\n",
    "            r\"\\n[A-Z \\'\\-\\n\\.’]+\\naNUMBERaSIXaSIGNa[\\n ][0-9]+( aNUMBERaSIXaSIGNa)?\\n\"\n",
    "        ), ' '))\n",
    "        patterns.append(\n",
    "            (re.compile(r\"\\nCHAPTER [A-Z -]+\\naNUMBERaSIXaSIGNa [0-9]+\\n\"),\n",
    "             ' '))\n",
    "        patterns.append(\n",
    "            (re.compile(r\"\\nCHAPTER [A-Z -]+\\n[0-9]+ aNUMBERaSIXaSIGNa\\n\"),\n",
    "             ' '))\n",
    "        patterns.append((re.compile(\n",
    "            r\"Get free e-books and video tutorials at www\\.passuneb\\.com\"),\n",
    "                         ' '))\n",
    "    patterns.append((re.compile(r'-\\n'), ''))\n",
    "\n",
    "    if remove_new_lines:\n",
    "        patterns.append((re.compile(r'\\n'), ' '))\n",
    "        patterns.append((re.compile(r'  '), ' '))\n",
    "\n",
    "    patterns.append((re.compile(r'\\. ?\"'), ' . \"'))\n",
    "    patterns.append((re.compile(r\"\\. ?'\"), \" . '\"))\n",
    "\n",
    "    if remove_hyphens:\n",
    "        patterns.append((re.compile(r'[—–\\-/\\\\\\_]'), ' '))\n",
    "    else:\n",
    "        patterns.append((re.compile(r'[/\\\\\\_]'), ' '))\n",
    "\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    for input_file in listdir(input_directory):\n",
    "        if input_file[-4:] != '.txt':\n",
    "            print(\n",
    "                \"The directory should contain only the txt files! Can't read file: \",\n",
    "                input_file)\n",
    "            return\n",
    "\n",
    "        with open(input_directory + '/' + input_file, 'rt',\n",
    "                  encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        for pattern, replacement in patterns:\n",
    "            text = re.sub(pattern, replacement, text)\n",
    "\n",
    "        if to_lower:\n",
    "            text = text.lower()\n",
    "\n",
    "        with open(output_directory + '/' + input_file[:-4] + '_prepared.txt',\n",
    "                  'wt',\n",
    "                  encoding='utf-8') as file:\n",
    "            file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code is available in <a href=\"https://github.com/12jerek34jeremi/harry_potter.git\">this repository</a> This function is in utils module of hpcw package, which is in that repository in hpcw directory. You can download and import this easily by executing those commands: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/12jerek34jeremi/harry_potter.git#subdirectory=hpcw\n",
    "from hpcw.utils import prepare_harry_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can just execute below two cells to install and import all necessary things at once. (I assume that you have torch, numpy and tqdm alredy installed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/12jerek34jeremi/harry_potter.git#subdirectory=hpcw\n",
    "!pip install nltk==3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from hpcw.datasets.words_batch_dataset import WordsBatchDataset\n",
    "from hpcw.datasets.one_item_dataset import OneItemDataset\n",
    "from hpcw.corpus import Corpus\n",
    "from hpcw.models.embedding import Embedding\n",
    "from hpcw.models.words_batch import WordsBatch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "from typing import List, Dict, Tuple\n",
    "from datetime import datetime\n",
    "from hpcw.utils import count_distance\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   While copying function code from repository I removed all comments, so that cell is not so long and while reading this notebook  you do not need to scroll so much. Click <a href=\"https://github.com/12jerek34jeremi/harry_potter/blob/main/hpcw/hpcw/utils.py\">here</a> to view whole function code with comments.<br>\n",
    "   \n",
    "   Above function(prepare_harry_book) except for removing chapter titles, this function does a little bit more. Two or more dots, next to each other or separated only by space, and … at the end of the word are changed to three dots after a space. (maybe.. --> maybe ... , maybe… --> maybe ..., maybe. . .  -->   maybe ...). This way in the corpus there won't be multiple words representing the same thing.\n",
    "\n",
    "   While working on above function, I discovered a strange behaviour of word_tokenize function from nltk.tokenize. When a sentence is inside quotations marks, then the final word, dot and second quotation mark are considered as three different words. That's providing that there are no spaces between dot and second quotation mark. When there is such a space, then dot is consider as part of the final word. Dot is also consider as part of the word when “ or ” quotation marks are used (not \"). I worked with nltk version 3.7. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk==3.7\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``', 'I', 'have', 'a', 'cat', '.', \"''\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(' \"I have a cat.\" ') # now it is okey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``', 'I', 'have', 'a', 'cat.', '``']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(' \"I have a cat. \" ') # now it is not working as I would like it to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“', 'I', 'have', 'a', 'cat.', '“']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('“I have a cat.“')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   I actually missed that at the first, so in first version of corpus next to words \"cat\", \"wizard\" or \"harry\", there were words \"cat.\", \"wizard.\" and \"harry.\". Not to let that happens, I modified prepare_harry_book function a little bit. Now this function first change all both “ and ” quotation mark to \". Then it inserts space after and before a dot, if after the dot there is a quotation mark. This way word_tokenize always recognize dot as separate word, and there aren't as many types of quotation marks in the corpus. The above function does a bit more, if you are interested you can read <a href = \"https://github.com/12jerek34jeremi/harry_potter/blob/main/hpcw/hpcw/utils.py\">description </a>which is at the top of the function body.\n",
    "   \n",
    "   Unfortunately, because of copy rights, I can't share with you all txt files I worked with. I can only share a first fragment of each file. (Usually online bookstore show first chapter, or first few paragraphs of book for free, this way encouraging to buy this book. For the rest of the book you need to of course pay.) In <a href=\"https://drive.google.com/drive/folders/1kqV_LBNNCqwcJYvG-yzdyIFjjqzbaNIx?usp=sharing\">this google drive folder</a> there are all files I used or produced while working on this project. In this folder in harry_potter_books/prepared_txt directory you can find all those fragment. Anyway, this is an exemplary fragment of a file I worked with while training a model:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mr. and mrs. dursley, of number four, privet drive, were proud to say that they were perfectly normal, thank you very much. they were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. mr. dursley was the director of a firm called grunnings, which made drills. he was a big, beefy man with hardly any neck, although he did have a very large mustache. mrs. dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. the dursleys had a small son called dudley and in their opinion there was no finer boy anywhere. the dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. they didn't think they could bear it if anyone found out about the potters. mrs. potter was mrs. dursley's sister, but they hadn't met for several years; in fact, mrs. dursley pretended she didn't have a sister, because her sister and her good for nothing husband were as undursleyish as it was possible to be. the dursleys shuddered to think what the neighbors would say if the potters arrived in the street. the dursleys knew that the potters had a small son, too, but they had never even seen him. this boy was another good reason for keeping the potters away; they didn't want dudley mixing with a child like that. when mr. and mrs. dursley woke up on the dull, gray tuesday our story starts, there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country. mr. dursley hummed as he picked out his most boring tie for work, and mrs. dursley gossiped away happily as she wrestled a screaming dudley into his high chair. none of them noticed a large, tawny owl flutter past the window. at half past eight, mr. dursley picked up his briefcase, pecked mrs. dursley on the cheek,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Step 2\n",
    "   So after removing all unwanted stuff from files, we would like to give each file an unique id, which I'm going to call a token. This is done by this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(directory: str,\n",
    "                      save_file: str = None,\n",
    "                      min_documents: int = 1) -> Dict[str, int]:\n",
    "    \n",
    "    pattern = re.compile(r'^-?[0-9]*[,.]?[0-9]*$')\n",
    "    sets = []\n",
    "    rejected = 0\n",
    "    dictionary = {}\n",
    "    rejected_words = []\n",
    "    for i in range(1, 8):\n",
    "        file_path = directory + '/harry_potter_' + str(i) + '_prepared.txt'\n",
    "        if not os.path.exists(file_path):\n",
    "            print(\"Could not find file \", file_path)\n",
    "            return None\n",
    "        with open(file_path, 'rt', encoding='utf-8') as file:\n",
    "            sets.append(set(word_tokenize(file.read())))\n",
    "\n",
    "    if len(sets) < min_documents:\n",
    "        print(\n",
    "            f\"There are only {len(sets)} documents in this directory and you require from each word to be in at lest\"\n",
    "            f\" {min_documents} documents!\")\n",
    "        return None\n",
    "    min_documents -= 1\n",
    "    # if word needs to be in at least 3 documents, I need to check if it appears in at least 2 otherdocu ments\n",
    "    i = 0\n",
    "    if min_documents != 0:\n",
    "        i = 3\n",
    "        for i, my_set in enumerate(sets):\n",
    "            to_remove = set()\n",
    "            for word in my_set:\n",
    "                sets_with_the_word = []\n",
    "                n = 0\n",
    "\n",
    "                # start of checking if word is in at least min_documents nr of documents\n",
    "                for other_set in sets[:i] + sets[i + 1:]:\n",
    "                    if word in other_set:\n",
    "                        n += 1\n",
    "                        sets_with_the_word.append(other_set)\n",
    "                        if n == min_documents:\n",
    "                            break\n",
    "                # end of checking if word is in at least min_documents nr of documents\n",
    "\n",
    "                if n < min_documents:\n",
    "                    for other_set in sets_with_the_word:\n",
    "                        other_set.remove(word)\n",
    "                    to_remove.add(word)\n",
    "                    if word.istitle():\n",
    "                        dictionary[word] = 0\n",
    "                    elif pattern.match(word) is not None:\n",
    "                        dictionary[word] = 1\n",
    "                    else:\n",
    "                        dictionary[word] = 2\n",
    "                    rejected += 1\n",
    "                    rejected_words.append(word)\n",
    "            my_set -= to_remove\n",
    "\n",
    "        print(f\"Rejected {rejected} words.\")\n",
    "        print(\"Rejected words:\")\n",
    "        print(rejected_words)\n",
    "\n",
    "    whole_set = set()\n",
    "    for my_set in sets:\n",
    "        whole_set.update(my_set)\n",
    "\n",
    "    del sets\n",
    "\n",
    "    for word in whole_set:\n",
    "        dictionary[word] = i\n",
    "        i += 1\n",
    "\n",
    "    if save_file is not None:\n",
    "        with open(save_file, 'wb') as file:\n",
    "            pickle.dump(dictionary, file)\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above function splits each text file into words using word_tokenize function and gives each unique word an uinique id. It creates a dictionary which looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0, 'wizzard': 1, 'harry': 2, 'music': 3}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exemplatory_corpus = {\"cat\": 0, 'wizzard': 1, 'harry': 2, 'music': 3}\n",
    "exemplatory_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, real dictionary is much bigger. Having created the dictionary, the above function then saves it in a file, which filepath is described by 'save_file' argument, using a pickle module.\n",
    "\n",
    "   The above function has option of including into a corpus only words which are in at least some number of files, but finally I didn't use this. If you are interested you can always read a whole function in <a href = \"https://github.com/12jerek34jeremi/harry_potter/blob/main/hpcw/hpcw/utils.py\">description </a>.\n",
    "\n",
    "   You can download dictionary produced by this function from <a href=\"https://drive.google.com/drive/folders/1kqV_LBNNCqwcJYvG-yzdyIFjjqzbaNIx?usp=sharing\">this google drive folder</a> in which there are all data I used or produced while working on this project. If you downloaded above folder you can get this dictionary executing these commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'re': 0,\n",
       " 'awakened': 1,\n",
       " 'traced': 2,\n",
       " 'dejected': 3,\n",
       " 'deprimo': 4,\n",
       " 'streetlamps': 5,\n",
       " 'nearsighted': 6,\n",
       " 'emporium': 7,\n",
       " 'waters': 8,\n",
       " 'cardboard': 9,\n",
       " 'kept': 10,\n",
       " 'furious': 11,\n",
       " 'sundown': 12,\n",
       " 'punished': 13,\n",
       " 'journalists': 15,\n",
       " 'suggesting': 16,\n",
       " 'readiness': 17,\n",
       " 'tentacle': 18,\n",
       " 'backfiring': 19,\n",
       " 'hollowed': 20,\n",
       " 'slopingshouldered': 21,\n",
       " 'sacked': 22,\n",
       " 'oozing': 23,\n",
       " 'niche': 24,\n",
       " 'blossom': 25,\n",
       " 'watchers': 26,\n",
       " 'shell': 27,\n",
       " 'stunted': 28,\n",
       " 'finest': 29,\n",
       " 'notorious': 30,\n",
       " 'fairer': 31,\n",
       " 'pumpkin': 32,\n",
       " 'hoisted': 33,\n",
       " 'lightheaded': 34,\n",
       " 'confetti': 35,\n",
       " 'tendrils': 36,\n",
       " 'notoriously': 37,\n",
       " 'providing': 38,\n",
       " 'plums': 39,\n",
       " 'spotty': 40,\n",
       " 'prizing': 41,\n",
       " 'nurtured': 42,\n",
       " 'occupy': 43,\n",
       " 'cried': 44,\n",
       " 'campaigned': 45,\n",
       " 'erected': 46,\n",
       " 'followers': 47,\n",
       " 'quarry': 48,\n",
       " 'slope': 49,\n",
       " 'someday': 50,\n",
       " 'foulest': 51,\n",
       " 'houseelf': 52,\n",
       " 'steering': 53,\n",
       " 'voters': 54,\n",
       " 'dottiness': 55,\n",
       " 'one': 56,\n",
       " 'pleasurable': 57,\n",
       " 'etuunnel': 58,\n",
       " 'holey': 59,\n",
       " 'acknowledges': 60,\n",
       " 'upcoming': 61,\n",
       " 'pursuits': 62,\n",
       " 'blissful': 63,\n",
       " 'collapse': 64,\n",
       " 'doe': 65,\n",
       " 'overlong': 66,\n",
       " 'legilimency': 67,\n",
       " 'inadvertently': 68,\n",
       " 'babysit': 69,\n",
       " 'results': 70,\n",
       " 'chant': 71,\n",
       " 'pomfrey': 72,\n",
       " 'companion': 73,\n",
       " 'ostentatiously': 74,\n",
       " 'bott': 75,\n",
       " 'novelties': 76,\n",
       " 'tumblers': 77,\n",
       " 'slithering': 78,\n",
       " 'restful': 79,\n",
       " 'lightless': 80,\n",
       " 'identified': 81,\n",
       " 'product': 82,\n",
       " 'history': 83,\n",
       " 'grammatica': 84,\n",
       " 'deliverin': 85,\n",
       " 'singularly': 86,\n",
       " 'stowing': 87,\n",
       " 'unexpected': 88,\n",
       " 'matron': 89,\n",
       " 'cavity': 90,\n",
       " 'cue': 91,\n",
       " 'promoted': 92,\n",
       " 'exhausted': 93,\n",
       " 'glugged': 94,\n",
       " 'trumpet': 95,\n",
       " 'saints': 96,\n",
       " 'snare': 97,\n",
       " 'blasts': 98,\n",
       " 'candidate': 99,\n",
       " 'stout': 100,\n",
       " 'froglike': 101,\n",
       " 'assuage': 102,\n",
       " 'understandably': 103,\n",
       " 'numerology': 104,\n",
       " 'misdirect': 105,\n",
       " \"'mazing\": 106,\n",
       " 'rancorous': 107,\n",
       " 'unlike': 108,\n",
       " 'smitten': 109,\n",
       " 'inigo': 110,\n",
       " 'ours': 111,\n",
       " 'interested': 112,\n",
       " 'tasks': 113,\n",
       " 'eaters': 114,\n",
       " 'trickier': 115,\n",
       " 'coding': 116,\n",
       " 'wickedest': 117,\n",
       " 'carved': 118,\n",
       " 'grayish': 119,\n",
       " 'rustled': 120,\n",
       " 'herbione': 121,\n",
       " 'lacquered': 122,\n",
       " 'tentatively': 123,\n",
       " 'pinches': 124,\n",
       " 'weigh': 125,\n",
       " 'sprang': 126,\n",
       " 'belief': 127,\n",
       " 'escapators': 128,\n",
       " 'drained': 129,\n",
       " 'windpipe': 130,\n",
       " 'mistaken': 131,\n",
       " 'pie': 132,\n",
       " 'fowl': 133,\n",
       " 'doubtless': 134,\n",
       " 'robbery': 135,\n",
       " 'cuts': 136,\n",
       " 'map': 137,\n",
       " 'inhaled': 138,\n",
       " 'retorting': 139,\n",
       " 'spit': 140,\n",
       " 'afterthought': 141,\n",
       " 'age': 142,\n",
       " 'maker': 143,\n",
       " 'decipher': 144,\n",
       " 'preserving': 145,\n",
       " 'aroun': 146,\n",
       " 'surprises': 147,\n",
       " 'irresistibly': 148,\n",
       " 'downhill': 149,\n",
       " 'experiment': 150,\n",
       " 'glass': 151,\n",
       " 'lamenting': 152,\n",
       " 'mermen': 153,\n",
       " 'bitty': 154,\n",
       " 'infects': 155,\n",
       " 'terrors': 156,\n",
       " 'protuberance': 157,\n",
       " 'community': 158,\n",
       " 'o.w.l': 159,\n",
       " 'scrap': 160,\n",
       " 'widening': 161,\n",
       " 'pupil': 162,\n",
       " 'furtive': 163,\n",
       " 'underage': 164,\n",
       " 'sincere': 165,\n",
       " 'aaaargh': 166,\n",
       " 'eve': 167,\n",
       " 'outside': 168,\n",
       " 'mutters': 169,\n",
       " 'prick': 170,\n",
       " 'tarantulas': 171,\n",
       " 'breaths': 172,\n",
       " 'raspberries': 173,\n",
       " 'aisles': 174,\n",
       " 'darkening': 175,\n",
       " 'sweatshirt': 176,\n",
       " 'frisbees': 177,\n",
       " 'fortune': 178,\n",
       " 'neighbors': 179,\n",
       " 'dumped': 180,\n",
       " 'woss': 181,\n",
       " 'takeoff': 182,\n",
       " 'revulsion': 183,\n",
       " 'purplish': 184,\n",
       " 'invisibly': 185,\n",
       " 'rides': 186,\n",
       " 'draining': 187,\n",
       " 'goblet': 188,\n",
       " 'yell': 189,\n",
       " 'frank': 190,\n",
       " 'elfric': 191,\n",
       " 'holiday': 192,\n",
       " 'problem': 193,\n",
       " 'happier': 194,\n",
       " 'hang': 195,\n",
       " 'flimsy': 196,\n",
       " 'dummy': 197,\n",
       " 'overrule': 198,\n",
       " 'cowed': 199,\n",
       " 'shacklebolt': 200,\n",
       " 'caughty': 201,\n",
       " 'onionlike': 202,\n",
       " 'bulbs': 203,\n",
       " 'mantra': 204,\n",
       " 'adn': 205,\n",
       " 'assistance': 206,\n",
       " 'soupspoon': 207,\n",
       " 'constrictor': 208,\n",
       " 'safely': 209,\n",
       " 'troupe': 210,\n",
       " 'bellies': 211,\n",
       " 'pompous': 212,\n",
       " 'rampaging': 213,\n",
       " 'potty': 214,\n",
       " 'betide': 215,\n",
       " 'mobile': 216,\n",
       " 'sportingly': 217,\n",
       " 'bole': 218,\n",
       " 'untouched': 219,\n",
       " 'quickening': 220,\n",
       " 'blonde': 221,\n",
       " 'brewing': 222,\n",
       " 'papery': 223,\n",
       " 'pod': 224,\n",
       " 'waterfall': 225,\n",
       " 'macmillan': 226,\n",
       " 'outline': 227,\n",
       " 'entirely': 228,\n",
       " 'opalescent': 229,\n",
       " 'warring': 230,\n",
       " 'tuft': 231,\n",
       " 'skele': 232,\n",
       " 'reignite': 233,\n",
       " 'baths': 234,\n",
       " 'surrounding': 235,\n",
       " 'opened': 236,\n",
       " 'sniffy': 237,\n",
       " 'doily': 238,\n",
       " 'enrage': 239,\n",
       " 'mr': 240,\n",
       " 'dog': 241,\n",
       " 'dreams': 242,\n",
       " 'de': 243,\n",
       " 'foully': 244,\n",
       " 'lounged': 245,\n",
       " 'bezoars': 246,\n",
       " 'notebooks': 247,\n",
       " 'rowle': 248,\n",
       " 'swang': 249,\n",
       " 'adjustment': 250,\n",
       " 'capturing': 251,\n",
       " 'oddity': 252,\n",
       " 'fused': 253,\n",
       " 'wing': 254,\n",
       " 'scuffling': 255,\n",
       " 'jeweled': 256,\n",
       " 'clutches': 257,\n",
       " 'groped': 258,\n",
       " 'vibrated': 259,\n",
       " 'certainty': 260,\n",
       " 'wouldn': 261,\n",
       " 'slumped': 262,\n",
       " 'entangled': 263,\n",
       " 'coldness': 264,\n",
       " 'halftrue': 265,\n",
       " 'irritate': 266,\n",
       " 'conflict': 267,\n",
       " 'cotton': 268,\n",
       " 'desirable': 269,\n",
       " 'dine': 270,\n",
       " 'goggles': 271,\n",
       " 'professorhead': 272,\n",
       " 'guffaws': 273,\n",
       " 'predicted': 274,\n",
       " 'extinguish': 275,\n",
       " 'windmills': 276,\n",
       " 'moldy': 277,\n",
       " 'intimidating': 278,\n",
       " 'inherited': 279,\n",
       " 'practices': 280,\n",
       " 'brawl': 281,\n",
       " 'denser': 282,\n",
       " 'cupids': 283,\n",
       " 'types': 284,\n",
       " 'pitching': 285,\n",
       " 'serpent': 286,\n",
       " 'hurtful': 287,\n",
       " 'unflattering': 288,\n",
       " 'pages': 289,\n",
       " 'sown': 290,\n",
       " 'station': 291,\n",
       " 'rosmerta': 292,\n",
       " 'lancelot': 293,\n",
       " 'ariana': 294,\n",
       " 'genteel': 295,\n",
       " 'aisle': 296,\n",
       " 'communicated': 297,\n",
       " 'past': 298,\n",
       " 'averse': 299,\n",
       " 'uninvestigated': 300,\n",
       " 'loathing': 301,\n",
       " 'materialize': 302,\n",
       " 'emphasized': 303,\n",
       " 'shamrocks': 304,\n",
       " 'diss': 305,\n",
       " 'silliest': 306,\n",
       " 'quid': 307,\n",
       " 'exuberantly': 308,\n",
       " 'cobbled': 309,\n",
       " 'uncommon': 310,\n",
       " 'fixedly': 311,\n",
       " 'negligently': 312,\n",
       " 'principles': 313,\n",
       " 'relinquishing': 314,\n",
       " 'chatter': 315,\n",
       " 'convention': 316,\n",
       " 'precaution': 317,\n",
       " 'reeling': 318,\n",
       " 'excruciatingly': 319,\n",
       " 'rapidly': 320,\n",
       " 'thoughtful': 321,\n",
       " 'chivvied': 322,\n",
       " 'flatteneed': 323,\n",
       " 'cravat': 324,\n",
       " 'sings': 325,\n",
       " 'steadying': 326,\n",
       " 'headache': 327,\n",
       " 'ean': 328,\n",
       " 'writhed': 329,\n",
       " 'offactly': 330,\n",
       " 'felt': 331,\n",
       " 'wardrobe': 332,\n",
       " 'toasted': 333,\n",
       " 'knight': 334,\n",
       " 'wiv': 335,\n",
       " 'key': 336,\n",
       " 'guidance': 337,\n",
       " 'reviewed': 338,\n",
       " 'sleeve': 339,\n",
       " 'stumbling': 340,\n",
       " 'crup': 341,\n",
       " 'waists': 342,\n",
       " \"'s'cuse\": 343,\n",
       " 'declaring': 344,\n",
       " 'believer': 345,\n",
       " 'structure': 346,\n",
       " 'vista': 347,\n",
       " 'somefink': 348,\n",
       " 'misty': 349,\n",
       " 'skinnier': 350,\n",
       " 'purplefaced': 351,\n",
       " 'glowering': 352,\n",
       " 'skeeter': 353,\n",
       " 'mousse': 354,\n",
       " 'herd': 355,\n",
       " 'talking': 356,\n",
       " 'swiping': 357,\n",
       " 'recognizing': 358,\n",
       " 'expectation': 359,\n",
       " 'bewildered': 360,\n",
       " 'assurances': 361,\n",
       " 'blaze': 362,\n",
       " 'encounters': 363,\n",
       " 'reverberating': 364,\n",
       " 'wen': 365,\n",
       " 'unwisely': 366,\n",
       " 'isolated': 367,\n",
       " 'vus': 368,\n",
       " 'dummies': 369,\n",
       " 'smacked': 370,\n",
       " 'endeavors': 371,\n",
       " 'headless': 372,\n",
       " 'bike': 373,\n",
       " 'rider': 374,\n",
       " 'cragg': 375,\n",
       " 'kickoff': 376,\n",
       " 'textbook': 377,\n",
       " 'mission': 378,\n",
       " 'algie': 379,\n",
       " 'turnips': 380,\n",
       " 'deafened': 381,\n",
       " 'veiled': 382,\n",
       " 'both': 383,\n",
       " 'airy': 384,\n",
       " 'greedy': 385,\n",
       " 'ex': 386,\n",
       " 'shifting': 387,\n",
       " 'brown': 388,\n",
       " 'bagpipe': 389,\n",
       " 'susan': 390,\n",
       " 'here': 391,\n",
       " 'incognito': 392,\n",
       " 'bumper': 393,\n",
       " 'cluttering': 394,\n",
       " 'effective': 395,\n",
       " 'wolf': 396,\n",
       " 'jinxing': 397,\n",
       " 'staggerin': 398,\n",
       " 'open': 399,\n",
       " 'corrected': 400,\n",
       " 'standby': 401,\n",
       " 'marked': 402,\n",
       " 'claims': 403,\n",
       " 'independent': 404,\n",
       " 'spoilsport': 405,\n",
       " 'spawned': 406,\n",
       " 'modify': 407,\n",
       " 'floors': 408,\n",
       " 'studded': 409,\n",
       " 'poking': 410,\n",
       " 'review': 411,\n",
       " 'aggression': 412,\n",
       " 'pronouncements': 413,\n",
       " 'graves': 414,\n",
       " 'obscured': 415,\n",
       " 'playstation': 416,\n",
       " 'rockets': 417,\n",
       " 'tobias': 418,\n",
       " 'dad': 419,\n",
       " 'variation': 420,\n",
       " 'burrow': 421,\n",
       " 'shyly': 422,\n",
       " 'undercover': 423,\n",
       " 'journeying': 424,\n",
       " 'creation': 425,\n",
       " 'quentin': 426,\n",
       " 'watched': 427,\n",
       " 'universe': 428,\n",
       " 'uneaten': 429,\n",
       " 'bright': 430,\n",
       " 'yours': 431,\n",
       " 'consoling': 432,\n",
       " 'jamming': 433,\n",
       " 'chained': 434,\n",
       " 'crates': 435,\n",
       " 'proudest': 436,\n",
       " 'signaling': 437,\n",
       " 'accelerating': 438,\n",
       " 'revolt': 439,\n",
       " 'remus': 440,\n",
       " 'suit': 441,\n",
       " 'scraps': 442,\n",
       " 'hotel': 443,\n",
       " 'equals': 444,\n",
       " 'notbe': 445,\n",
       " 'restlessly': 446,\n",
       " 'rhapsodizing': 447,\n",
       " 'bonfires': 448,\n",
       " 'joined': 449,\n",
       " 'factors': 450,\n",
       " 'roan': 451,\n",
       " 'unwound': 452,\n",
       " 'bang': 453,\n",
       " 'windblown': 454,\n",
       " 'indication': 455,\n",
       " 'mark': 456,\n",
       " 'liability': 457,\n",
       " 'smash': 458,\n",
       " 'unjust': 459,\n",
       " 'references': 460,\n",
       " 'marionette': 461,\n",
       " 'unceremoniously': 462,\n",
       " 'vividly': 463,\n",
       " 'robertses': 464,\n",
       " 'tunelessly': 465,\n",
       " 'concern': 466,\n",
       " 'wrought': 467,\n",
       " 'countercharm': 468,\n",
       " 'unplottable': 469,\n",
       " 'bravery': 470,\n",
       " 'lately': 471,\n",
       " 'blurry': 472,\n",
       " 'inflicting': 473,\n",
       " 'condensation': 474,\n",
       " 'readily': 475,\n",
       " 'increased': 476,\n",
       " 'compulsively': 477,\n",
       " 'detests': 478,\n",
       " 'anxiously': 479,\n",
       " 'explore': 480,\n",
       " 'wisest': 481,\n",
       " 'hallucination': 482,\n",
       " 'spinner': 483,\n",
       " 'miss': 484,\n",
       " 'sledges': 485,\n",
       " 'beckoning': 486,\n",
       " 'slush': 487,\n",
       " 'stowed': 488,\n",
       " \"y'are\": 489,\n",
       " 'corks': 490,\n",
       " 'jumpy': 491,\n",
       " 'clockwise': 492,\n",
       " 'firebolts': 493,\n",
       " 'nifflers': 494,\n",
       " 'ever': 495,\n",
       " 'space': 496,\n",
       " 'stuck': 497,\n",
       " 'limitations': 498,\n",
       " 'mostly': 499,\n",
       " 'simmer': 500,\n",
       " 'outmoded': 501,\n",
       " 'unwelcome': 502,\n",
       " 'activate': 503,\n",
       " 'galumphing': 504,\n",
       " 'dictate': 505,\n",
       " 'waist': 506,\n",
       " 'bud': 507,\n",
       " 'pellet': 508,\n",
       " 'snatcher': 509,\n",
       " 'supporters': 510,\n",
       " 'fined': 511,\n",
       " 'undetected': 512,\n",
       " 'parvati': 513,\n",
       " 'pickling': 514,\n",
       " 'treading': 515,\n",
       " 'edam': 516,\n",
       " 'mounds': 517,\n",
       " 'teaches': 518,\n",
       " 'ave': 519,\n",
       " 'stirred': 520,\n",
       " 'tantalizingly': 521,\n",
       " 'haunted': 522,\n",
       " 'endeavoring': 523,\n",
       " 'untucked': 524,\n",
       " 'jars': 525,\n",
       " 'illustrations': 526,\n",
       " 'surest': 527,\n",
       " 'winced': 528,\n",
       " 'upholding': 529,\n",
       " 'snuffbox': 530,\n",
       " 'trod': 531,\n",
       " 'progressed': 532,\n",
       " 'closeted': 533,\n",
       " 'baraabas': 534,\n",
       " 'frenzied': 535,\n",
       " 'humoring': 536,\n",
       " 'messed': 537,\n",
       " 'taught': 538,\n",
       " 'bestial': 539,\n",
       " 'cavelike': 540,\n",
       " 'contradicted': 541,\n",
       " 'tureen': 542,\n",
       " 'children': 543,\n",
       " 'whence': 544,\n",
       " 'really': 545,\n",
       " 'nightmarishly': 546,\n",
       " 'battling': 547,\n",
       " 'plenty': 548,\n",
       " 'atrium': 549,\n",
       " 'sorting': 550,\n",
       " 'copiously': 551,\n",
       " 'dismal': 552,\n",
       " 'sniffing': 553,\n",
       " 'aging': 554,\n",
       " 'problems': 555,\n",
       " 'conversationally': 556,\n",
       " 'potionmaking': 557,\n",
       " 'incantato': 558,\n",
       " 'victoire': 559,\n",
       " 'losing': 560,\n",
       " 'mantelpiece': 561,\n",
       " 'burdens': 562,\n",
       " 'gifts': 563,\n",
       " 'hyacinths': 564,\n",
       " 'watersnakes': 565,\n",
       " 'contender': 566,\n",
       " 'unmanageable': 567,\n",
       " 'bleeder': 568,\n",
       " 'tomatoes': 569,\n",
       " 'grew': 570,\n",
       " 'prejudiced': 571,\n",
       " 'weakly': 572,\n",
       " 'tremble': 573,\n",
       " 'succession': 574,\n",
       " 'manufacturers': 575,\n",
       " 'administer': 576,\n",
       " 'inspect': 577,\n",
       " 'diaphragm': 578,\n",
       " 'cursing': 579,\n",
       " 'slighter': 580,\n",
       " 'burly': 581,\n",
       " 'polyjuice': 582,\n",
       " 'foes': 583,\n",
       " 'creevey': 584,\n",
       " 'spanish': 585,\n",
       " 'hornets': 586,\n",
       " 'burp': 587,\n",
       " 'build': 588,\n",
       " 'bushy': 589,\n",
       " 'department': 590,\n",
       " 'marks': 591,\n",
       " 'millimeter': 592,\n",
       " 'practically': 593,\n",
       " 'cheeky': 594,\n",
       " 'appealingly': 595,\n",
       " 'farmhouse': 596,\n",
       " 'stale': 597,\n",
       " 'rattled': 598,\n",
       " 'enthusiastically': 599,\n",
       " 'brooms': 600,\n",
       " 'untie': 601,\n",
       " 'accepting': 602,\n",
       " 'bathed': 603,\n",
       " 'unbelievable': 604,\n",
       " 'coziness': 605,\n",
       " 'portree': 606,\n",
       " 'dormant': 607,\n",
       " 'choke': 608,\n",
       " 'ties': 609,\n",
       " 'collection': 610,\n",
       " 'turnout': 611,\n",
       " 'safety': 612,\n",
       " 'obliged': 613,\n",
       " 'impressive': 614,\n",
       " 'corruption': 615,\n",
       " 'riotously': 616,\n",
       " 'grilles': 617,\n",
       " 'gryffndor': 618,\n",
       " 'spent': 619,\n",
       " 'backwards': 620,\n",
       " 'binns': 621,\n",
       " 'model': 622,\n",
       " 'images': 623,\n",
       " 'spawns': 624,\n",
       " 'grunt': 625,\n",
       " 'astounded': 626,\n",
       " 'jammed': 627,\n",
       " 'poundage': 628,\n",
       " 'create': 629,\n",
       " 'punched': 630,\n",
       " 'weasley': 631,\n",
       " 'cobwebs': 632,\n",
       " 'theatrically': 633,\n",
       " 'tally': 634,\n",
       " 'bloodshed': 635,\n",
       " 'coped': 636,\n",
       " 'tribe': 637,\n",
       " 'denial': 638,\n",
       " 'regulated': 639,\n",
       " 'fast': 640,\n",
       " 'bedraggled': 641,\n",
       " '49': 642,\n",
       " 'smattering': 643,\n",
       " 'drifted': 644,\n",
       " 'lightheartedness': 645,\n",
       " 'slughorn': 646,\n",
       " 'throw': 647,\n",
       " 'posts': 648,\n",
       " 'wide': 649,\n",
       " 'holds': 650,\n",
       " 'stop': 651,\n",
       " 'corner': 652,\n",
       " 'remainder': 653,\n",
       " 'soothingly': 654,\n",
       " 'quick': 655,\n",
       " 'troublemakers': 656,\n",
       " 'perceived': 657,\n",
       " 'clumsily': 658,\n",
       " 'anchors': 659,\n",
       " 'banner': 660,\n",
       " 'brandnew': 661,\n",
       " 'bearlike': 662,\n",
       " 'successful': 663,\n",
       " 'rue': 664,\n",
       " 'spells': 665,\n",
       " 'giving': 666,\n",
       " 'thethered': 667,\n",
       " 'sprouts': 668,\n",
       " 'skepticism': 669,\n",
       " 'adjusted': 670,\n",
       " 'profile': 671,\n",
       " 'unwonted': 672,\n",
       " 'someone': 673,\n",
       " 'knarl': 674,\n",
       " 'rubber': 675,\n",
       " 'colored': 676,\n",
       " 'townsfolk': 677,\n",
       " 'assistants': 678,\n",
       " \"'ad\": 679,\n",
       " 'bark': 680,\n",
       " 'rinds': 681,\n",
       " 'dancin': 682,\n",
       " 'coating': 683,\n",
       " 'astonished': 684,\n",
       " 'luxembourg': 685,\n",
       " 'fightin': 686,\n",
       " 'trespassed': 687,\n",
       " 'brace': 688,\n",
       " 'overdosed': 689,\n",
       " 'share': 690,\n",
       " 'replaced': 691,\n",
       " 'universal': 692,\n",
       " 'inee': 693,\n",
       " 'iced': 694,\n",
       " 'copse': 695,\n",
       " 'jiggered': 696,\n",
       " 'vying': 697,\n",
       " 'halfpolished': 698,\n",
       " 'asphodel': 699,\n",
       " 'sipping': 700,\n",
       " 'pondered': 701,\n",
       " 'imprinted': 702,\n",
       " 'subtle': 703,\n",
       " 'employees': 704,\n",
       " 'airwaves': 705,\n",
       " 'drip': 706,\n",
       " 'senile': 707,\n",
       " 'stile': 708,\n",
       " 'selfabsorption': 709,\n",
       " 'yule': 710,\n",
       " 'rhubarb': 711,\n",
       " 'prostrate': 712,\n",
       " 'roaring': 713,\n",
       " 'test': 714,\n",
       " 'maisie': 715,\n",
       " 'wair': 716,\n",
       " 'wrestled': 717,\n",
       " 'feasting': 718,\n",
       " 'shocking': 719,\n",
       " 'counseled': 720,\n",
       " 'nancy': 721,\n",
       " 'quavering': 722,\n",
       " 'throttle': 723,\n",
       " 'adding': 724,\n",
       " 'disperse': 725,\n",
       " 'vincent': 726,\n",
       " 'reprieved': 727,\n",
       " 'flay': 728,\n",
       " 'defend': 729,\n",
       " 'profited': 730,\n",
       " 'screamed': 731,\n",
       " 'committing': 732,\n",
       " 'sapling': 733,\n",
       " 'crevices': 734,\n",
       " 'forgive': 735,\n",
       " 'unpopular': 736,\n",
       " 'bunches': 737,\n",
       " 'riddle': 738,\n",
       " 'judging': 739,\n",
       " 'bowed': 740,\n",
       " 'kitten': 741,\n",
       " 'tombstone': 742,\n",
       " \"'cinderella\": 743,\n",
       " 'support': 744,\n",
       " 'benson': 745,\n",
       " 'closing': 746,\n",
       " 'death': 747,\n",
       " 'whiteblond': 748,\n",
       " 'stocking': 749,\n",
       " 'peashooter': 750,\n",
       " 'falls': 751,\n",
       " 'spoonful': 752,\n",
       " 'bustling': 753,\n",
       " \"'right\": 754,\n",
       " 'agonized': 755,\n",
       " 'tempered': 756,\n",
       " 'prongs': 757,\n",
       " 'dim': 758,\n",
       " 'smashed': 759,\n",
       " 'refilling': 760,\n",
       " 'benamed': 761,\n",
       " 'haggis': 762,\n",
       " 'tradition': 763,\n",
       " 'sliver': 764,\n",
       " 'deflecting': 765,\n",
       " 'barty': 766,\n",
       " 'chortling': 767,\n",
       " 'lament': 768,\n",
       " 'hunching': 769,\n",
       " 'trouser': 770,\n",
       " 'dumpy': 771,\n",
       " 'fifty': 772,\n",
       " 'headmistresses': 773,\n",
       " 'upheld': 774,\n",
       " 'cheat': 775,\n",
       " 'reconnaissance': 776,\n",
       " 'lunge': 777,\n",
       " 'corpsefigure': 778,\n",
       " 'slender': 779,\n",
       " 'suicidal': 780,\n",
       " 'fing': 781,\n",
       " 'workshop': 782,\n",
       " 'screeched': 783,\n",
       " 'designed': 784,\n",
       " 'financial': 785,\n",
       " 'blended': 786,\n",
       " 'emmeline': 787,\n",
       " 'hatch': 788,\n",
       " 'lazy': 789,\n",
       " 'rapped': 790,\n",
       " 'imprecations': 791,\n",
       " 'identifying': 792,\n",
       " 'eyeglass': 793,\n",
       " 'a.m.': 794,\n",
       " 'petrify': 795,\n",
       " 'stroked': 796,\n",
       " 'poncho': 797,\n",
       " 'overcoming': 798,\n",
       " 'launch': 799,\n",
       " 'dazzle': 800,\n",
       " 'irresolute': 801,\n",
       " 'hereafter': 802,\n",
       " 'inventions': 803,\n",
       " 'manticore': 804,\n",
       " 'prolonged': 805,\n",
       " 'supposedly': 806,\n",
       " 'incalculable': 807,\n",
       " 'eaten': 808,\n",
       " 'scurryings': 809,\n",
       " 'wound': 810,\n",
       " 'ooooo': 811,\n",
       " 'utmost': 812,\n",
       " 'besides': 813,\n",
       " 'challenging': 814,\n",
       " 'exhibited': 815,\n",
       " 'never': 816,\n",
       " 'undefeated': 817,\n",
       " 'six': 818,\n",
       " 'demanding': 819,\n",
       " 'undressed': 820,\n",
       " 'perfected': 821,\n",
       " 'procedures': 822,\n",
       " 'array': 823,\n",
       " 'defensively': 824,\n",
       " 'massively': 825,\n",
       " 'eat': 826,\n",
       " 'graying': 827,\n",
       " 'destroyed': 828,\n",
       " 'frustratedly': 829,\n",
       " 'backflips': 830,\n",
       " 'superimposed': 831,\n",
       " 'explode': 832,\n",
       " 'unstick': 833,\n",
       " 'complaints': 834,\n",
       " 'cuppa': 835,\n",
       " 'gettin': 836,\n",
       " 'stove': 837,\n",
       " 'bought': 838,\n",
       " 'abrupt': 839,\n",
       " 'gummed': 840,\n",
       " 'jangled': 841,\n",
       " 'dobbs': 842,\n",
       " 'halfexpecting': 843,\n",
       " 'thirty': 844,\n",
       " 'patches': 845,\n",
       " 'booster': 846,\n",
       " 'wireless': 847,\n",
       " 'retort': 848,\n",
       " 'grub': 849,\n",
       " 'proofs': 850,\n",
       " 'vast': 851,\n",
       " 'extrarefined': 852,\n",
       " 'questionnaire': 853,\n",
       " 'rubied': 854,\n",
       " \"'wand\": 855,\n",
       " 'transform': 856,\n",
       " 'intrusion': 857,\n",
       " 'peoples': 858,\n",
       " 'hiya': 859,\n",
       " 'pumpkins': 860,\n",
       " 'cinders': 861,\n",
       " 'mischief': 862,\n",
       " 'fortresslike': 863,\n",
       " 'linking': 864,\n",
       " 'went': 865,\n",
       " 'windows': 866,\n",
       " 'okay': 867,\n",
       " 'newspaper': 868,\n",
       " 'oldest': 869,\n",
       " 'remember': 870,\n",
       " \"c'mere\": 871,\n",
       " 'befoul': 872,\n",
       " 'erratic': 873,\n",
       " 'gryffindorravenclaw': 874,\n",
       " 'wheeling': 875,\n",
       " 'sooty': 876,\n",
       " 'nicer': 877,\n",
       " 'legendary': 878,\n",
       " 'gardener': 879,\n",
       " '53': 880,\n",
       " 'trot': 881,\n",
       " 'vertical': 882,\n",
       " 'decades': 883,\n",
       " 'easing': 884,\n",
       " 'hopkirk': 885,\n",
       " 'slytherins': 886,\n",
       " 'delaney': 887,\n",
       " 'lucius': 888,\n",
       " 'sixteenyear': 889,\n",
       " 'furor': 890,\n",
       " 'crudely': 891,\n",
       " 'rulebreaking': 892,\n",
       " 'lied': 893,\n",
       " 'ld': 894,\n",
       " 'wounds': 895,\n",
       " 'gossip': 896,\n",
       " 'heartily': 897,\n",
       " 'producing': 898,\n",
       " 'refusal': 899,\n",
       " 'ribbons': 900,\n",
       " 'glimpse': 901,\n",
       " 'abused': 902,\n",
       " 'traitorously': 903,\n",
       " 'couple': 904,\n",
       " 'pillow': 905,\n",
       " 'wall': 906,\n",
       " 'rekindled': 907,\n",
       " 'stave': 908,\n",
       " 'fireworks': 909,\n",
       " 'mop': 910,\n",
       " 'breakthrough': 911,\n",
       " 'lolling': 912,\n",
       " 'wrangled': 913,\n",
       " 'porpington': 914,\n",
       " 'surroundings': 915,\n",
       " 'weirdly': 916,\n",
       " 'hesitant': 917,\n",
       " 'luxurious': 918,\n",
       " 'inseparable': 919,\n",
       " 'gabbling': 920,\n",
       " 'custard': 921,\n",
       " 'misting': 922,\n",
       " 'injust': 923,\n",
       " 'whirring': 924,\n",
       " 'b': 925,\n",
       " 'kenneth': 926,\n",
       " 'sardonically': 927,\n",
       " 'crinkled': 928,\n",
       " 'sniggered': 929,\n",
       " 'jerk': 930,\n",
       " 'specializes': 931,\n",
       " 'permetiez': 932,\n",
       " 'square': 933,\n",
       " 'holy': 934,\n",
       " 'ollivander': 935,\n",
       " 'embarrassed': 936,\n",
       " 'sympathize': 937,\n",
       " 'mouth': 938,\n",
       " 'dudders': 939,\n",
       " 'listeners': 940,\n",
       " 'smell': 941,\n",
       " 'disowned': 942,\n",
       " 'squeals': 943,\n",
       " 'arisen': 944,\n",
       " 'resided': 945,\n",
       " 'rifled': 946,\n",
       " 'prickly': 947,\n",
       " 'lighter': 948,\n",
       " 'cube': 949,\n",
       " \"i'd\": 950,\n",
       " 'numbness': 951,\n",
       " 'machine': 952,\n",
       " 'incendio': 953,\n",
       " 'rabbits': 954,\n",
       " 'scufflings': 955,\n",
       " 'kettleburn': 956,\n",
       " 'mell': 957,\n",
       " 'arcs': 958,\n",
       " 'handkerchiefs': 959,\n",
       " 'publishes': 960,\n",
       " 'gonglike': 961,\n",
       " 'foundations': 962,\n",
       " 'mortlake': 963,\n",
       " 'spite': 964,\n",
       " 'absorb': 965,\n",
       " 'unit': 966,\n",
       " 'marriages': 967,\n",
       " 'ado': 968,\n",
       " 'tighten': 969,\n",
       " 'coals': 970,\n",
       " 'furled': 971,\n",
       " 'wafted': 972,\n",
       " 'reseating': 973,\n",
       " 'bearings': 974,\n",
       " 'rictusempra': 975,\n",
       " 'gentlemen': 976,\n",
       " 'gnashing': 977,\n",
       " 'mischievously': 978,\n",
       " 'carrow': 979,\n",
       " \"'something\": 980,\n",
       " 'naturally': 981,\n",
       " 'thus': 982,\n",
       " 'salem': 983,\n",
       " 'purchase': 984,\n",
       " 'humorles': 985,\n",
       " 'waging': 986,\n",
       " 'shrewdly': 987,\n",
       " 'describes': 988,\n",
       " 'sandwich': 989,\n",
       " 'veered': 990,\n",
       " 'wildest': 991,\n",
       " 'straightforward': 992,\n",
       " 'moonstones': 993,\n",
       " 'reluctance': 994,\n",
       " 'progressing': 995,\n",
       " 'middle': 996,\n",
       " 'deprive': 997,\n",
       " 'slurped': 998,\n",
       " 'separately': 999,\n",
       " 'wrecked': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAIN_DATA_DIR = 'data' # change this for filepath of the downloaded folder\n",
    "with open(MAIN_DATA_DIR+'/dictionary/second_dictionary_30_04.pickle', 'rb') as file:\n",
    "    corpus_dictionary = pickle.load(file)\n",
    "corpus_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21371"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   In file <a href = \"https://github.com/12jerek34jeremi/harry_potter/blob/main/test_corpus.ipynb\">test_corpus.ipynb</a> i was analysing this dictionary to make sure that there are no weird words there and that most of the words occur multiple times in books. Good I did it, otherwise I hadn't known that I have words like \"cat.\" in the corpus and I hadn't fixed prepere_harry_book function. :D\n",
    "   \n",
    "   While working on this project after a while I came to conclusion that I would like to have an easy way to transform word into a token and token into a word. I wrote this class, which \\__getitem__ method looks on argument datatype and returns a token for given word or word corresponding to given token. Here is this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    def __init__(self, dictionary_filepath: str):\n",
    "        try:\n",
    "            with open(dictionary_filepath, 'rb') as file:\n",
    "                self.dictionary = pickle.load(file)\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                \"There was an error while trying to read dictionary from file: \",\n",
    "                dictionary_filepath)\n",
    "            print(e)\n",
    "            return\n",
    "\n",
    "        self.__length = len(self.dictionary)\n",
    "        words = [None for _ in range(self.__length)]\n",
    "        for word, word_id in self.dictionary.items():\n",
    "            words[word_id] = word\n",
    "\n",
    "        if None in words:\n",
    "            print(\"Dictionary saved in file: \", dictionary_filepath,\n",
    "                  \" has a id gap.\")\n",
    "            print(\"There is no word assigned to id: \", words.index(None))\n",
    "            raise Exception(\"Id gap in dictionary.\")\n",
    "            return\n",
    "\n",
    "        self.__words = words\n",
    "\n",
    "    def __getitem__(self, index: str or int):\n",
    "        if isinstance(index, int):\n",
    "            return self.__words[index]\n",
    "        elif isinstance(index, str):\n",
    "            return self.dictionary[index]\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"Unsupported index type: \" + str(type(index)) +\n",
    "                \" (in __getitem__ function of Corpus class object)\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"Returns the number of words in dictionary. (max_id+1)\"\n",
    "        return self.__length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can easily convert tokens to words and words to tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token of word \"wizzard\" is  7093\n",
      "Token 7093 is assigned to token \"wizard\".\n"
     ]
    }
   ],
   "source": [
    "my_corpus = Corpus(MAIN_DATA_DIR+'/dictionary/second_dictionary_30_04.pickle')\n",
    "print('Token of word \"wizzard\" is ', my_corpus['wizard'])\n",
    "print('Token 7093 is assigned to token \"', my_corpus[7093], '\".', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usually, while copying code from repository, I removed all comments, so that cell isn't so long. <a href=\"https://github.com/12jerek34jeremi/harry_potter/blob/main/hpcw/hpcw/utils.py\">Here</a> you can view original code (written by me) with comments.\n",
    "\n",
    "## Step Three\n",
    "   Now we would like to have a way to transform a token to an embedding vector and to encode the embedding vector (to transform it back to a token). I used trainable embedding (torch.nn.Embedding) with embedding vectors of size (64,) for first transformation. For encoding I used fully-connected layers with three hidden layers. First hidden layer had 256 neurons, second hidden layer had 512 neurons and last hidden layer had 1024 neurons. \n",
    "\n",
    "![title](notebooks_data/embedding_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is implementation of such a network. As usually you can see this code with comments <a href=\"https://github.com/12jerek34jeremi/harry_potter/blob/main/hpcw/hpcw/models/embedding.py\">here</a>. While copying code from repository I removed comments and methods responsible for loading and saving. I did it so below cell is not so long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Jedrzej Chmiel\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 corpus_size: int,\n",
    "                 embedding_size: int,\n",
    "                 dropout_factor: float,\n",
    "                 sizes=[512, 1024, 2048]):\n",
    "\n",
    "        super().__init__()\n",
    "        self.__embedding = nn.Embedding(corpus_size, embedding_size)\n",
    "\n",
    "        self.__encoding = nn.ModuleList()\n",
    "        for input_dim, output_dim in zip([embedding_size] + sizes[:-1], sizes):\n",
    "            self.__encoding.extend([\n",
    "                nn.Linear(input_dim, output_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_factor)\n",
    "            ])\n",
    "        self.__encoding.append(nn.Linear(sizes[-1], corpus_size))\n",
    "\n",
    "        self.corpus_size = corpus_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.dropout_factor = dropout_factor\n",
    "        self.sizes = sizes\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def get_embedding(self) -> torch.nn.Embedding:\n",
    "        return self.__embedding\n",
    "\n",
    "    def to_dense(self, tokens: torch.Tensor):\n",
    "        return self.__embedding(tokens)\n",
    "\n",
    "    def words_probabilities(self, dense_embedding: torch.Tensor):\n",
    "        result = dense_embedding\n",
    "        for l in self.__encoding:\n",
    "            result = l(result)\n",
    "\n",
    "        return f.softmax(result, dim=-1)\n",
    "\n",
    "    def forward(self, dense_embedding: torch.Tensor):\n",
    "        \n",
    "        result = dense_embedding\n",
    "        for l in self.__encoding:\n",
    "            result = l(result)\n",
    "\n",
    "        return self.log_softmax(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create object of Embedding class you need to specify:\n",
    "1) corpus_size: The size of corpus, how many words there are in dictionary.\n",
    "\n",
    "2) embedding_size: The length of a dense vector which will represent a word\n",
    "\n",
    "3) dropout_factor: The dropout factor used in each hidden layer of encoding network.\n",
    "\n",
    "4) sizes: Sizes is list of lengths of consecutive hidden layers in encoding network. Encoding network is fully connected network used for transforming a dense vector back to the token.\n",
    "\n",
    "In our case (as shown in graph1) corpus_size is 21371, embedding_size is 64, dropout_factor is 0.18 and sizes is [256, 512, 1024]. I tried different options, I used embedding size of 32, 64 and 128. It turned out that 64 is the best options.\n",
    "\n",
    "Class embedding has method to_dense, which you can use to transform token to dense vector, and method word_propabilites, which can be used to transform embedding vector back to a token. Method word_propabilites returns a tensor, which each element denote the probability that given embedding vector corresponds to a token of this element's index. So if returned tensor looks like this:\n",
    "[[0.01, 0.02, 0.93, 0.1, 0.003, ..., 0.01]],\n",
    "then it means that for 93% passed dense_vector represent word of token 2 (because 0.93 is at position [0,2]). Method forward\n",
    "is really similar to method word_propabilites, just instead of probabilities  it returns natural logarithms of those probabilities.\n",
    "\n",
    "Below is shown how you can change words to tokens, tokens to embedding vectors and embedding vector back to a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_words:  ['you', \"'re\", 'a', 'wizard', ',', 'harry', '!']\n",
      "my_tokens:  tensor([21322, 10380, 18334,  7093,  5506, 14689,  6547])\n",
      "Shape of dense_vectors:  torch.Size([7, 64])\n",
      "Shape of words_propabilites:  torch.Size([7, 21371])\n",
      "encoded_tokens:  tensor([19707, 10671, 20937,  7214, 16014, 11981, 11981])\n",
      "encoded_word:  ['postage', 'ragged', 'cackle', 'afforded', 'lime', 'plant', 'plant']\n"
     ]
    }
   ],
   "source": [
    "my_words = ['you', \"'re\", 'a', 'wizard', ',', 'harry', '!']\n",
    "print(\"my_words: \", my_words)\n",
    "my_tokens = torch.tensor([my_corpus[word] for word in my_words], dtype=torch.long)\n",
    "print(\"my_tokens: \", my_tokens)\n",
    "my_embedding = Embedding(len(my_corpus), 64, 0.18, [256, 512, 1024])\n",
    "embedding_vectors = my_embedding.to_dense(my_tokens)\n",
    "print(\"Shape of dense_vectors: \", embedding_vectors.shape)\n",
    "words_propabilities = my_embedding.words_probabilities(dense_vectors)\n",
    "print(\"Shape of words_propabilites: \", words_propabilities.shape)\n",
    "encoded_tokens = torch.argmax(words_propabilities, dim=1)\n",
    "print(\"encoded_tokens: \", encoded_tokens)\n",
    "encoded_word = [my_corpus[token.item()] for token in encoded_tokens]\n",
    "print(\"encoded_word: \", encoded_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course this embedding is not trained at all, so predicted tokens and real tokens are completely different.<br>\n",
    "\n",
    "\n",
    "Let's remind terminology used in this notebook:<br>\n",
    "word - A string like 'harry', '.', or 'wizard'.<br>\n",
    "token - A natural number. Each unique word is assigned to an unique natural number called a token.<br>\n",
    "embedding_vector - A dense vector representing some word. It is implemented using one dimensional tensor.<br>\n",
    "\n",
    "## Step four\n",
    "At this moment embedding vectors are more a less sequence of random numbers. They don't decode any useful information, they aren't meaningful. To change that I used techinque called \"Batch of Words\". In this technique you are trying to predict a word by previous N words and following N words. Just like you are trying to fill a gap in a sentence. For example given words\n",
    "['Hogwart', 'is', 'the'] and words ['school', 'for', 'wizards'], we want to predict word 'best'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hogwart is the ---?--- school for wizzards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sketch of \"Batch of Words\" model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](notebooks_data/words_batch_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   As you can see we first change all words to tokens and then all tokens to embedding vectors. Then we use stack of two LSTM's to analyse N previous words. First input to LSTM cell is embedding vector of word 1, then embedding vector of word 2 and then embedding vector of word 3. We do the same with N following words, but here we input words in reverse order. First input to LSTM cell is embedding vector of token 7, then embedding vector of token 6 and lastly embedding vector of token 5. Then we create a context vector by concatenating last hidden states of second layer of both LSTM's stack. Then there is a fully connected layer with ReLU activation, and lastly one more fully connected layer, which output is embedding vector. We want this produced embedding vector to be the same what embedding vector of word we are predicting.\n",
    "\n",
    "   Each LSTM cell and first fully-connected layer has dropout applied. This dropout is for two things. First, we want our Batch of Words model to predict word instead of learning sequences by heart. Secondly, which is more important, this dropout enforces learning of embedding. In embedding there is no dropout applied. Because of that embedding parameters are updated more often than other model parameters. This enforce embedding to encode meaningful information in embedding vectors. We need to remember that primary purpose of Batch of Words model is to train embedding, not to predict a word.\n",
    "   \n",
    "   Lastly, while training on given sequence we will not update parameters of embedding of word that is predicted. (Embedding vector of word, which is predicted, is done with torch.no_grad(). )\n",
    "   \n",
    "   Here is an implementation of a Word of Batch model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordsBatch(nn.Module):  #second version\n",
    "    def __init__(self,\n",
    "                 embedding: Embedding,\n",
    "                 hidden_state_size: int,\n",
    "                 dropout_factor: float,\n",
    "                 sequence_length: int,\n",
    "                 dense_layer_size: int = 1024):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        embedding_size = embedding.embedding_size\n",
    "        self.lstm_before = nn.LSTM(embedding_size,\n",
    "                                   hidden_state_size,\n",
    "                                   2,\n",
    "                                   dropout=dropout_factor,\n",
    "                                   batch_first=True)\n",
    "        self.lstm_after = nn.LSTM(embedding_size,\n",
    "                                  hidden_state_size,\n",
    "                                  2,\n",
    "                                  dropout=dropout_factor,\n",
    "                                  batch_first=True)\n",
    "        self.tail = nn.Sequential(\n",
    "            nn.Linear(hidden_state_size * 2, dense_layer_size), nn.ReLU(),\n",
    "            nn.Dropout(dropout_factor),\n",
    "            nn.Linear(dense_layer_size, embedding_size))\n",
    "        self.sequence_length = sequence_length\n",
    "        self.hidden_state_size = hidden_state_size\n",
    "        self.dropout_factor = dropout_factor\n",
    "        self.dense_layer_size = dense_layer_size\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        input = self.embedding.to_dense(input)\n",
    "        _, (hiddens_before,\n",
    "            _) = self.lstm_before(input[:, :self.sequence_length, :])\n",
    "        _, (hiddens_after,\n",
    "            _) = self.lstm_after(input[:, self.sequence_length:, :])\n",
    "        return self.tail(\n",
    "            torch.stack([\n",
    "                torch.cat((hiddens_before[1, i], hiddens_after[1, i]), dim=0)\n",
    "                for i in range(batch_size)\n",
    "            ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view whole class code <a href=\"https://github.com/12jerek34jeremi/harry_potter/blob/main/hpcw/hpcw/models/words_batch.py\">here</a>, while copying from repository I removed all comments and method responsible for saving and loading from file. To create a Batch of Words model you need to specify following things:\n",
    "1) embedding: The object of Embedding class. It will be used to convert tokens for dense vectors.\n",
    "\n",
    "2) hidden_state_size: The size of hidden_state in both layers of both LSTM's stacks.\n",
    "\n",
    "3) dropout_factor: Dropout factor in LSTM layers and in first fully connected layer.\n",
    "\n",
    "4) sequence_length: How many words before and after will be used to predict the middle word. If sequence_length is 3 then input to this model should be three words before and three words after. (N)\n",
    "\n",
    "  On the above graph hidden_state_size is 96 and sequence_length is 3. Input to a \"forward\" function is expected a tensor of shape (N, 2*s_l), where N is batch size and s_l is sequence_length. First part of second axis are words before word which is to be predicted and second part of second axis are words after word which is to be predicted in reversed order. Data type of the input tensor should be \"long\" (intiger numbers).\n",
    "  \n",
    "   Here is an example of how to use WordsBatch class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences:\n",
      "[['hogwart', 'is', 'the', 'best', 'school', 'for', 'wizards'],\n",
      " ['when', 'aunt', 'petunia', 'and', 'dudley', 'had', 'run']]\n",
      "sentences in tokens:\n",
      "[[7418, 9501, 3589, 20972, 6054, 9838, 3089],\n",
      " [15916, 13125, 19518, 13483, 15871, 13211, 20101]]\n",
      "input_sequence:\n",
      "tensor([[ 7418,  9501,  3589,  3089,  9838,  6054],\n",
      "        [15916, 13125, 19518, 20101, 13211, 15871]])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "my_corpus = Corpus(MAIN_DATA_DIR+'/dictionary/second_dictionary_30_04.pickle')\n",
    "sentences = [['hogwart', 'is', 'the', 'best', 'school', 'for', 'wizards'],\n",
    "            ['when', 'aunt', 'petunia', 'and', 'dudley', 'had', 'run']]\n",
    "print(\"sentences:\")\n",
    "pprint(sentences)\n",
    "sentences = [[my_corpus[word] for word in sentence] for sentence in sentences]\n",
    "print(\"sentences in tokens:\")\n",
    "pprint(sentences)\n",
    "input_sequence = torch.tensor([sentence[0:3] + sentence[6:3:-1] for sentence in sentences], dtype=torch.long)\n",
    "print(\"input_sequence:\")\n",
    "pprint(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_embedding = Embedding(len(my_corpus), 64, 0.18, [256, 512, 1024])\n",
    "my_words_batch = WordsBatch(my_embedding, hidden_state_size=96,\n",
    "                            dropout_factor=0.18, sequence_length=3, dense_layer_size=256)\n",
    "embedding_vectors = my_words_batch(input_sequence)\n",
    "embedding_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In well trained Batch of Words model, the above two embedding vectors should be similar to embedding vectors of words 'best' and 'and'. Before we start training the model, we should create a dataset that will allow us to easily get input sequences. We are going of course use Harry Potter books to obtain those sequences. Here is an implementation of such dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordsBatchDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 book_filapath: str,\n",
    "                 dictionary: dict,\n",
    "                 sequence_length: int,\n",
    "                 transform: callable = None,\n",
    "                 target_transform: callable = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.__transform = transform\n",
    "        self.__target_transform = target_transform\n",
    "        self.__sequence_length = sequence_length\n",
    "\n",
    "        try:\n",
    "            with open(book_filapath, 'rt', encoding='UTF-8') as file:\n",
    "                words = word_tokenize(file.read())\n",
    "        except Exception as e:\n",
    "            print(\"There was an error while trying to read words from file: \",\n",
    "                  book_filapath)\n",
    "            print(e)\n",
    "            return\n",
    "        self.tokens = torch.tensor([dictionary[word] for word in words],\n",
    "                                   dtype=torch.long)\n",
    "        self.__length = len(self.tokens) - (2 * sequence_length)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "        index = index + self.__sequence_length\n",
    "        X = torch.cat(\n",
    "            (self.tokens[index - self.__sequence_length:index],\n",
    "             torch.flip(\n",
    "                 self.tokens[index + 1:index + self.__sequence_length + 1],\n",
    "                 (0, ))),\n",
    "            dim=0)\n",
    "        y = self.tokens[index]\n",
    "        if self.__transform is not None:\n",
    "            X = self.__transform(X)\n",
    "        if self.__target_transform is not None:\n",
    "            y = self.__target_transform(y)\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \n",
    "        return self.__length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again you can view whole class code <a href=\"https://github.com/12jerek34jeremi/harry_potter/blob/main/hpcw/hpcw/datasets/words_batch_dataset.py\">here</a>, while copying from repository I removed all comments, co cell is not so long. This class take one file, splits it to words using word_tokenize function from nltk.tokenize, then transforms all words to tokens using passed dictionary. Calling \\__getitem__(i) returns a tuple. First element of this tuple is input_sequence consisting of tokens of words number i, i+1, i+2, i+3, i+6, i+5m i+4 (if sequence_length is 3). Second element of that tuple is token of word number i+4. Number of word is order of word in file. So calling \\__getitem__(0) returns tuple, which first element of this tuple is input_sequence consisting of first, second, third, fifth, sixth and seventh words' tokens (if sequence_length is 3). Second element of that tuple is token of fourth word.\n",
    "\n",
    "To create WordsBatchDataset object we need to specify following things:\n",
    "\n",
    "1) book_filapath: file path to file from which to read, should be .txt file with UTF-8 encoding.\n",
    "\n",
    "2) dictionary: dictionary of tokens's of each word. Like {'cat':0, 'wizard':1, ''hermione': 2, ...}\n",
    "\n",
    "3) sequence_length: how many words before and after are used to predict middle word.\n",
    "\n",
    "4) transform: function to be applied on each input in \\__getitem__ method.\n",
    "\n",
    "5) target_transform: function to be applied on each target in \\__getitem__ method.\n",
    "\n",
    "Let's take a look how can you use this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18334,  9589,  8131, 12024,  3589, 13952]), tensor(1055), 184)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus = Corpus(MAIN_DATA_DIR+'/dictionary/second_dictionary_30_04.pickle')\n",
    "words_batch_dataset = WordsBatchDataset(MAIN_DATA_DIR+'/harry_potter_books/prepared_txt/harry_potter_5_prepared.txt',\n",
    "                                       my_corpus.dictionary, 3)\n",
    "(X, y) = words_batch_dataset[14]\n",
    "(X, y, len(words_batch_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18472,  6494, 12483,  8502,   740, 21322]), tensor(9154), 98483)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time for functions that can test and train our Batch of Words model. Those are that functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_words_batch(model:WordsBatch, datasets: List[OneItemDataset], batch_size=2048) -> float:\n",
    "    mse = 0.0\n",
    "    with torch.no_grad():\n",
    "      loss_function = nn.MSELoss(reduction='sum')\n",
    "      for dataset in datasets:\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "        for X, y in loader:\n",
    "          X = X.to(DEVICE)\n",
    "          y = y.to(DEVICE)\n",
    "          y = model.embedding.to_dense(y)\n",
    "          pred = model(X)\n",
    "          loss = loss_function(pred, y)\n",
    "          mse +=  loss.item()\n",
    "    \n",
    "    total_length = sum([len(dataset) for dataset in datasets])\n",
    "    mse = mse / total_length\n",
    "    return mse\n",
    "\n",
    "def train_words_batch(model:WordsBatch, datasets: List[OneItemDataset], batch_size: int, epochs: int,\n",
    "                    optimizer: optim.Optimizer, saves_dir:str = None, results:Dict[str, int or float] = None,\n",
    "                    start_epoch:int = 0):\n",
    "    \n",
    "    model.train()\n",
    "    loss_function = nn.MSELoss()\n",
    "    loaders = [DataLoader(dataset, batch_size, shuffle=True) for dataset in datasets]\n",
    "    if saves_dir is not None:\n",
    "        if not os.path.exists(saves_dir):\n",
    "            os.makedirs(saves_dir)\n",
    "        with open(saves_dir+'/results.pickle', 'wb') as file:\n",
    "                    pickle.dump(results, file)\n",
    "        with open(saves_dir+'/results.txt', 'wt') as file:\n",
    "            for key, item in results.items():\n",
    "                file.write(key + ': ' + str(item) + '\\n')\n",
    "\n",
    "    end_epoch = start_epoch+epochs\n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        for i,loader in enumerate(loaders):\n",
    "            print(f\"Epoch {epoch}/{end_epoch}, dataset {i+1}/7\")\n",
    "            for X, y in tqdm(loader, desc=\"batch: \"):\n",
    "                X = X.to(DEVICE)\n",
    "                with torch.no_grad():\n",
    "                    y = model.embedding.to_dense(y.to(DEVICE))\n",
    "                pred = model(X)\n",
    "                loss = loss_function(pred, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        if saves_dir is not None:\n",
    "            model.save(saves_dir+'/'+f\"words_batch_epoch_{epoch}.pth\")\n",
    "            if results is not None:\n",
    "                mse = test_words_batch(model, datasets)\n",
    "                print(f\"MSE is: {mse}\")\n",
    "                results[f'mse_after_epoch_{epoch}'] = mse\n",
    "                with open(saves_dir+'/results.pickle', 'wb') as file:\n",
    "                    pickle.dump(results, file)\n",
    "                with open(saves_dir+'/results.txt', 'at') as file:\n",
    "                    file.write(f'mse_after_epoch_{epoch} : {mse}\\n')\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are function from <a href=\"https://github.com/12jerek34jeremi/harry_potter/blob/main/training_embedding.ipynb\">this notebook</a> that I used to train and test Batch of words. As always, while copying code I removed all comments, so cell is not so long. Function test_words_batch is just usual function for testing a model. You pass model and datasets and you get Mean Squered Error. Exception is that instead of passing a dataset you pass list of dataset. Model is tested on each example from each dataset. One dataset represents one book.\n",
    "\n",
    "   Function train_words_batch is a little bit more advanced. It has option to test and (or) save model after each epoch. Not only it tests, but also saves results (Those are function from this notebook that I used to train and test Batch of words. As always, while copying code I removed all comments so cell is not so long. Function test_words_batch is just usual function for testing a model. You pass model and datasets and you get Mean Squerd Error. Exception is that instead of passing a dataset you pass list of dataset. Model is tested on each example from each dataset. One dataset represents one book.\n",
    "\n",
    "Function train_words_batch is a little bit more advanced. It has option to test and (or) save model after each epoch. Not only it tests, but also saves results (consequtives Mean Squered Errors) in a folder specified by save_dir argument.\n",
    "\n",
    "I trained first epoch with Adam optimizer. Adam has advantage of very quickly finding optimum. It's weakness is that, this is usually a local optimum. So after first epoch I changed optimizer for SGD. I was first increasing learning rate, then decreasing it. Finally I managed to decrese Mean Squere Error from 64 to 37. Here are results:) Mean Squered Error in a folder specified by save_dir argument.\n",
    "   \n",
    "   I trained first epoch with Adam optimizer. Adam has advantage of very quickly finding optimum. It's weakness is that, this is usually a local optimum. So after first epoch I changed optimizer for SGD. I was first increasing learning rate, then decreasing it. Finally, I managed to decrease Mean Squered Error from 64 to 37. Here are results:\n",
    "   \n",
    "sequence_length: 6<br>\n",
    "hidden_state_size: 96<br>\n",
    "words_batch_dropout_factor: 0.18<br>\n",
    "corpus_size: 21371<br>\n",
    "embedding_size: 64<br>\n",
    "embedding_dropout_factor: 0.18<br>\n",
    "dense_layer_size: 256<br>\n",
    "embedding_sizes: [128, 512]<br>\n",
    "mse_initial: 64.29942370265994<br>\n",
    "mse_after_epoch_0: 52.60520227320573<br>\n",
    "mse_after_epoch_1: 52.30913876929527<br>\n",
    "mse_after_epoch_2: 52.20851488967295<br>\n",
    "mse_after_epoch_3: 52.14135190074598<br>\n",
    "mse_after_epoch_4: 51.950624448872446<br>\n",
    "mse_after_epoch_5: 51.83675593595767<br>\n",
    "mse_after_epoch_6: 51.75410130974805<br>\n",
    "mse_after_epoch_7: 51.65097760170359<br>\n",
    "mse_after_epoch_8: 51.5586491620811<br>\n",
    "mse_after_epoch_9: 51.474882154022865<br>\n",
    "mse_after_epoch_10: 51.31758543956555<br>\n",
    "mse_after_epoch_11: 51.15598995923584<br>\n",
    "mse_after_epoch_12: 50.901749362907715<br>\n",
    "mse_after_epoch_13: 50.761164667025525<br>\n",
    "mse_after_epoch_14: 50.6291833403558<br>\n",
    "mse_after_epoch_15: 50.302834932244075<br>\n",
    "mse_after_epoch_16: 49.23443390332594<br>\n",
    "mse_after_epoch_17: 48.140573859643034<br>\n",
    "mse_after_epoch_18: 47.41930640960561<br>\n",
    "mse_after_epoch_19: 46.79732099527478<br>\n",
    "mse_after_epoch_20: 46.36616314413035<br>\n",
    "mse_after_epoch_21: 45.62561718447804<br>\n",
    "mse_after_epoch_22: 45.139281925774924<br>\n",
    "mse_after_epoch_23: 44.81519067466301<br>\n",
    "mse_after_epoch_24: 44.20030591168072<br>\n",
    "mse_after_epoch_25: 43.94495067460654<br>\n",
    "mse_after_epoch_26: 43.58491693399181<br>\n",
    "mse_after_epoch_27: 43.34388368685374<br>\n",
    "mse_after_epoch_28: 43.03487803247719<br>\n",
    "mse_after_epoch_29: 42.85478947218181<br>\n",
    "mse_after_epoch_30: 42.62419891597224<br>\n",
    "mse_after_epoch_31: 42.31260645505537<br>\n",
    "mse_after_epoch_32: 42.15380063517384<br>\n",
    "mse_after_epoch_33: 41.99196345051434<br>\n",
    "mse_after_epoch_34: 41.80021012155426<br>\n",
    "mse_after_epoch_35: 41.64912227409203<br>\n",
    "mse_after_epoch_36: 41.548523581275845<br>\n",
    "mse_after_epoch_37: 41.44337065349304<br>\n",
    "mse_after_epoch_38: 41.379112584165014<br>\n",
    "mse_after_epoch_39: 41.15036443472681<br>\n",
    "mse_after_epoch_40: 41.07060245736525<br>\n",
    "mse_after_epoch_41: 40.94660271939221<br>\n",
    "mse_after_epoch_42: 40.90915044349521<br>\n",
    "mse_after_epoch_43: 40.75535101599081<br>\n",
    "mse_after_epoch_44: 40.796668749926134<br>\n",
    "mse_after_epoch_45: 40.76526953376724<br>\n",
    "mse_after_epoch_46: 40.71127561151163<br>\n",
    "mse_after_epoch_47: 40.63315269411893<br>\n",
    "mse_after_epoch_48: 40.54427154381052<br>\n",
    "mse_after_epoch_49: 40.4493670253836<br>\n",
    "mse_after_epoch_50: 40.450810619282<br>\n",
    "mse_after_epoch_51: 39.71720223014681<br>\n",
    "mse_after_epoch_52: 39.617287283676376<br>\n",
    "mse_after_epoch_53: 39.5290350125415<br>\n",
    "mse_after_epoch_54: 39.46635166450212<br>\n",
    "mse_after_epoch_55: 39.41381587797716<br>\n",
    "mse_after_epoch_56: 39.378572202022674<br>\n",
    "mse_after_epoch_57: 39.349328670231074<br>\n",
    "mse_after_epoch_58: 39.34410934306521<br>\n",
    "mse_after_epoch_59: 39.290910236723725<br>\n",
    "mse_after_epoch_60: 39.266370457509794<br>\n",
    "mse_after_epoch_61: 37.20075500264407<br>\n",
    "mse_after_epoch_62: 37.170874836596276<br>\n",
    "mse_after_epoch_63: 37.160861972624396<br>\n",
    "mse_after_epoch_64: 37.10656308982189<br>\n",
    "mse_after_epoch_65: 37.098737885057865<br>\n",
    "mse_after_epoch_66: 37.08980483848128<br>\n",
    "mse_after_epoch_67: 37.089030974289486<br>\n",
    "mse_after_epoch_68: 37.08737508550147<br>\n",
    "mse_after_epoch_69: 37.0662691855884<br>\n",
    "mse_after_epoch_70: 37.06335852333475<br>\n",
    "mse_after_epoch_71: 37.06076176541749<br>\n",
    "mse_after_epoch_72: 37.05545056397271<br>\n",
    "mse_after_epoch_73: 37.05236029294468<br>\n",
    "mse_after_epoch_74: 37.05236029294468<br>\n",
    "mse_after_epoch_75: 37.05236029294468<br>\n",
    "mse_after_epoch_76: 37.05236029294468<br>\n",
    "mse_after_epoch_77: 37.05236029294468<br>\n",
    "mse_after_epoch_78: 37.05236029294468<br>\n",
    "mse_after_epoch_79: 37.044358156189766<br>\n",
    "mse_after_epoch_80: 37.04276683518385<br>\n",
    "mse_after_epoch_81: 37.04116837418348<br>\n",
    "mse_after_epoch_82: 37.04079893858515<br>\n",
    "mse_after_epoch_83: 37.04012796820178<br>\n",
    "mse_after_epoch_84: 37.071379672974864<br>\n",
    "mse_after_epoch_85: 37.06680836325128<br>\n",
    "mse_after_epoch_86: 37.062975492660655<br>\n",
    "mse_after_epoch_87: 37.05020294115353<br>\n",
    "mse_after_epoch_88: 37.051222440869964<br>\n",
    "mse_after_epoch_89: 37.0348309864466<br>\n",
    "mse_after_epoch_90: 37.033666933066726<br>\n",
    "mse_after_epoch_91: 37.02917806208983<br>\n",
    "mse_after_epoch_92: 37.023281119788976<br>\n",
    "mse_after_epoch_93: 37.02126619926795<br>\n",
    "mse_after_epoch_94: 37.025456303378974<br>\n",
    "mse_after_epoch_95: 37.026549120344676<br>\n",
    "mse_after_epoch_96: 37.0149139624427<br>\n",
    "mse_after_epoch_97: 37.00937711785647<br>\n",
    "mse_after_epoch_98: 37.01284947134004<br>\n",
    "mse_after_epoch_99 : 46.80461858202937<br>\n",
    "mse_after_epoch_100 : 52.68448140688683<br><br><br><br><br>\n",
    "\n",
    "And here are final notes:<br>\n",
    "epoch 0 was trained using adam optimizer<br>\n",
    "epoch 1,2,3 was trained using SGD, lr=0.001<br>\n",
    "epoch 4,5,6 was trained using SGD, lr=0.005<br>\n",
    "epoch 7,8,9 was trained using SGD, lr=0.01<br>\n",
    "epoch 10,11 was trained using SGD, lr=0.05<br>\n",
    "epoch 12,13,14 was trained using SGD, lr=0.1<br>\n",
    "epoch 15,16,...,24 was trained using SGD, lr=1.0<br>\n",
    "epoch 25,27,...,34 was trained using SGD, lr=1.0<br>\n",
    "epoch 35,36,.., 44 was trained using SGD, lr=1.0<br>\n",
    "epoch 44,45,..., 51 was trained using SGD, lr=0.5<br>\n",
    "epoch 51, 52, …, 60 was trained using SGD, lr=0.1<br>\n",
    "epoch 61,62,63  was trained using SGD, lr=0.05<br>\n",
    "epoch 64,65  was trained using SGD, lr=0.01<br>\n",
    "Epoch 66, 67, 68 was trained using SGD, lr=0.005<br>\n",
    "Epoch 69,70,71 was trained using SGD, lr=0.03<br>\n",
    "Epoch 72,73 was trained using SGD, lr=0.007<br>\n",
    "<br>\n",
    "\tPreviously batch size was 16, now it is changed for 64<br>\n",
    "<br>\n",
    "Epoch 74,75,76,77,78 was trained using SGD, lr=0.001<br>\n",
    "Epoch 79, 80, 81, 82, 83 was trained using SGD, lr=0.01<br>\n",
    "Epoch 84,...,93 was trained using SGD, lr=0.05<br>\n",
    "Epochs 94, .., 98 was trained using SGD, lr=0.075<br>\n",
    "<br>\n",
    "\tChange batch for 4<br>\n",
    "Epoch 99, 100 was trained using new Adam<br><br><br><br>\n",
    "\n",
    "And here are results plotted on a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpcw.utils as ut\n",
    "import pickle\n",
    "MAIN_DATA_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2160 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(MAIN_DATA_DIR+'/results/results.pickle', 'rb') as file:\n",
    "    results = pickle.load(file)\n",
    "ut.plot_mse(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now is the most interesting part. I choose 4 embedding from training: embedding after first epoch, embedding after epoch 34, embedding after epoch 61 and embedding after epoch 93. I wrote a simple <a href=\"https://github.com/12jerek34jeremi/harry_potter/blob/main/hpcw/hpcw/utils.py\">function</a> called count_distance that counts distance between two vectors. Distance between two vectors here is a sum of squares of differences of consecutive elements (a dot product of difference of vectors). It turned out that at first, with initial embedding, distance between nouns, verbs and adjectives is random. But after 93 epochs of training nouns are closer to other nouns than to verbs, verbs are closer to other verbs than to nouns and so on. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_initial = Embedding(corpus_size = len(my_corpus), embedding_size = 64, sizes=[256, 512, 1024], dropout_factor=0.18)\n",
    "embedding0 = Embedding(corpus_size = len(my_corpus), embedding_size = 64, sizes=[256, 512, 1024], dropout_factor=0.18)\n",
    "embedding0.load_embedding(MAIN_DATA_DIR + '/models/embedding_embedding0.pth')\n",
    "embedding34 = Embedding(corpus_size = len(my_corpus), embedding_size = 64, sizes=[256, 512, 1024], dropout_factor=0.18)\n",
    "embedding34.load_embedding(MAIN_DATA_DIR + '/models/embedding_embedding34.pth')\n",
    "embedding61 = Embedding(corpus_size = len(my_corpus), embedding_size = 64, sizes=[256, 512, 1024], dropout_factor=0.18)\n",
    "embedding61.load_embedding(MAIN_DATA_DIR + '/models/embedding_embedding61.pth')\n",
    "embedding93 = Embedding(corpus_size = len(my_corpus), embedding_size = 64, sizes=[256, 512, 1024], dropout_factor=0.18)\n",
    "embedding93.load_embedding(MAIN_DATA_DIR + '/models/embedding_embedding93.pth')\n",
    "# Embedding class has option of loading and saving just the embedding part (without encoding).\n",
    "# In above code I'm loading from file embedding state after epoch 0, 34, 61 and 93."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [('cat', 'dog'), ('cat', 'going'), ('hermione', 'water'), ('hermione', 'harry'),\n",
    "         ('is', 'being'), ('is', 'was'), ('hagrid', 'dumbledore'), ('snake', 'snakes'),\n",
    "         ('book', 'brilliant'), ('food', 'voldemort'), ('girl', 'boy'), ('girls', 'boys'),\n",
    "        ('school', 'run')]\n",
    "\n",
    "def check_distances(words: List[Tuple[str, str]], corpus: Corpus, embedding:Embedding):\n",
    "  for word1, word2 in words:  \n",
    "    dist = count_distance(word1, word2, corpus, embedding)\n",
    "    print(f\"    Distance between words '{word1}' and '{word2}' is {dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For embedding_initial: \n",
      "    Distance between words 'cat' and 'dog' is 148.19186401367188\n",
      "    Distance between words 'cat' and 'going' is 163.54542541503906\n",
      "    Distance between words 'hermione' and 'water' is 128.1963653564453\n",
      "    Distance between words 'hermione' and 'harry' is 122.0250473022461\n",
      "    Distance between words 'is' and 'being' is 123.58283996582031\n",
      "    Distance between words 'is' and 'was' is 157.10104370117188\n",
      "    Distance between words 'hagrid' and 'dumbledore' is 144.09664916992188\n",
      "    Distance between words 'snake' and 'snakes' is 142.73486328125\n",
      "    Distance between words 'book' and 'brilliant' is 81.66374206542969\n",
      "    Distance between words 'food' and 'voldemort' is 193.65582275390625\n",
      "    Distance between words 'girl' and 'boy' is 80.12884521484375\n",
      "    Distance between words 'girls' and 'boys' is 154.5997314453125\n",
      "    Distance between words 'school' and 'run' is 113.10707092285156\n"
     ]
    }
   ],
   "source": [
    "print(\"For embedding_initial: \")\n",
    "check_distances(words, my_corpus, embedding_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For embedding0: \n",
      "    Distance between words 'cat' and 'dog' is 188.56365966796875\n",
      "    Distance between words 'cat' and 'going' is 159.94679260253906\n",
      "    Distance between words 'hermione' and 'water' is 124.99183654785156\n",
      "    Distance between words 'hermione' and 'harry' is 87.04646301269531\n",
      "    Distance between words 'is' and 'being' is 155.7615203857422\n",
      "    Distance between words 'is' and 'was' is 111.06465148925781\n",
      "    Distance between words 'hagrid' and 'dumbledore' is 114.62118530273438\n",
      "    Distance between words 'snake' and 'snakes' is 136.7913055419922\n",
      "    Distance between words 'book' and 'brilliant' is 134.72833251953125\n",
      "    Distance between words 'food' and 'voldemort' is 121.21263885498047\n",
      "    Distance between words 'girl' and 'boy' is 93.92500305175781\n",
      "    Distance between words 'girls' and 'boys' is 139.14169311523438\n",
      "    Distance between words 'school' and 'run' is 194.46804809570312\n"
     ]
    }
   ],
   "source": [
    "print(\"For embedding0: \")\n",
    "check_distances(words, my_corpus, embedding0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For embedding34: \n",
      "    Distance between words 'cat' and 'dog' is 180.727294921875\n",
      "    Distance between words 'cat' and 'going' is 166.03314208984375\n",
      "    Distance between words 'hermione' and 'water' is 103.7860336303711\n",
      "    Distance between words 'hermione' and 'harry' is 37.58720779418945\n",
      "    Distance between words 'is' and 'being' is 136.8767852783203\n",
      "    Distance between words 'is' and 'was' is 71.04869079589844\n",
      "    Distance between words 'hagrid' and 'dumbledore' is 58.269596099853516\n",
      "    Distance between words 'snake' and 'snakes' is 131.8248291015625\n",
      "    Distance between words 'book' and 'brilliant' is 129.81053161621094\n",
      "    Distance between words 'food' and 'voldemort' is 115.80277252197266\n",
      "    Distance between words 'girl' and 'boy' is 86.43671417236328\n",
      "    Distance between words 'girls' and 'boys' is 136.47256469726562\n",
      "    Distance between words 'school' and 'run' is 182.268310546875\n"
     ]
    }
   ],
   "source": [
    "print(\"For embedding34: \")\n",
    "check_distances(words, my_corpus, embedding34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For embedding61: \n",
      "    Distance between words 'cat' and 'dog' is 181.21087646484375\n",
      "    Distance between words 'cat' and 'going' is 165.40618896484375\n",
      "    Distance between words 'hermione' and 'water' is 104.39942932128906\n",
      "    Distance between words 'hermione' and 'harry' is 35.331451416015625\n",
      "    Distance between words 'is' and 'being' is 130.61114501953125\n",
      "    Distance between words 'is' and 'was' is 64.57110595703125\n",
      "    Distance between words 'hagrid' and 'dumbledore' is 46.249244689941406\n",
      "    Distance between words 'snake' and 'snakes' is 130.7272491455078\n",
      "    Distance between words 'book' and 'brilliant' is 133.10012817382812\n",
      "    Distance between words 'food' and 'voldemort' is 110.18196105957031\n",
      "    Distance between words 'girl' and 'boy' is 84.8621826171875\n",
      "    Distance between words 'girls' and 'boys' is 127.60108184814453\n",
      "    Distance between words 'school' and 'run' is 161.7185821533203\n"
     ]
    }
   ],
   "source": [
    "print(\"For embedding61: \")\n",
    "check_distances(words, my_corpus, embedding61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For embedding93: \n",
      "    Distance between words 'cat' and 'dog' is 180.9871063232422\n",
      "    Distance between words 'cat' and 'going' is 165.05465698242188\n",
      "    Distance between words 'hermione' and 'water' is 104.21701049804688\n",
      "    Distance between words 'hermione' and 'harry' is 34.99916076660156\n",
      "    Distance between words 'is' and 'being' is 130.53807067871094\n",
      "    Distance between words 'is' and 'was' is 64.80520629882812\n",
      "    Distance between words 'hagrid' and 'dumbledore' is 45.41228103637695\n",
      "    Distance between words 'snake' and 'snakes' is 130.7606201171875\n",
      "    Distance between words 'book' and 'brilliant' is 133.3353729248047\n",
      "    Distance between words 'food' and 'voldemort' is 109.78778076171875\n",
      "    Distance between words 'girl' and 'boy' is 84.70751953125\n",
      "    Distance between words 'girls' and 'boys' is 127.25785827636719\n",
      "    Distance between words 'school' and 'run' is 161.63497924804688\n"
     ]
    }
   ],
   "source": [
    "print(\"For embedding93: \")\n",
    "check_distances(words, my_corpus, embedding93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see distance between words \"hermione\" and \"harry\" was at the beginning 122.0250473022461. Embedding learnt that they are both nouns of similar meanings (both are names). So after epoch 93 distance between those two words is 34.99916076660156.\n",
    "\n",
    "   Initial distance between words \"is\" and \"was\" was 157.10104370117188. After 93 epoch it decreased to 64.80520629882812. Distance between words 'is' and 'being' is bigger, namely 130.53807067871094. But it is not 180. It kind of makes sense. You can say \"Car is destroyed.\" or \"Car was destroyed.\" and it sounds good. But sentence \"Car being destroyed\" without a context doesn't make sense.\n",
    "\n",
    "   Also, initial distance between words 'school' and 'run' was 113.10707092285156. One is noun, second is verb, so distance between them should be bigger. And after 93 epochs it is, namely 161.63497924804688.\n",
    "   \n",
    "   Of course, some things does not make sense. For example, distance between words \"cat\" and \"dog\" is 180, they are far away each other. Both are names of animals, they should be close. The same situation is with words \"snake\" and \"snakes\", they should be close to each other. Results are good, but I think not good enough. My plan is now, before going further to train encoding, is to use transformers and Batch of Words model instead of LSTM's to train embedding. And then we can go further.\n",
    "   \n",
    "   That's it. I hope you enjoyed the reading. If you have some questions, or you want to hire a ML developer/researcher, you can write to me using this email address: jedrzej.chmiel.ml@gmail.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}